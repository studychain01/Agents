{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Text Processing Workflow\n",
        "\n",
        "This notebook demonstrates a LangGraph workflow that classifies text, extracts entities, and generates summaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "from typing import TypedDict, List \n",
        "from langgraph.graph import StateGraph, END \n",
        "from langchain.prompts import PromptTemplate \n",
        "from langchain_openai import ChatOpenAI \n",
        "from langchain.schema import HumanMessage \n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "from IPython.display import display, Image \n",
        "\n",
        "from dotenv import load_dotenv \n",
        "\n",
        "load_dotenv()\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class State(TypedDict): \n",
        "    text: str \n",
        "    classification: str \n",
        "    entities: List[str]\n",
        "    summary: str\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classification_node(state: State):\n",
        "    ''' Classify text into one of the categories: News, Blog, Research, or Other '''\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        #defining the input variables\n",
        "        input_variables=[\"text\"],\n",
        "\n",
        "        template=\"Classify the following text into one of the categories: News, Blog, Research, or Other.\\n\\nText:{text}\\n\\nCategory:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    classification = llm.invoke([message]).content.strip()\n",
        "    return {\"classification\": classification}\n",
        "\n",
        "def entity_extraction_node(state: State):\n",
        "    '''Extract all the entities (Person, Organization, Location) from the text'''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Extract all the entities (Person, Organization, Location) from the following text. Provide the result as a comma-seperated list. \\n\\nText:{text}\\n\\nEntities:\"\n",
        "    )\n",
        "\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    entities = llm.invoke([message]).content.strip().split(\".\")\n",
        "    return {\"entities\": entities}\n",
        "\n",
        "def summarization_node(state: State):\n",
        "    ''' Summarize the text in one short sentence '''\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"Summarize the following text in one short sentence. .\\n\\nText:{text}\\n\\nSummary:\"\n",
        "    )\n",
        "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
        "    summary = llm.invoke([message]).content.strip()\n",
        "    return {\"summary\": summary}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the workflow\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes to the graph\n",
        "workflow.add_node(\"classification\", classification_node)\n",
        "workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
        "workflow.add_node(\"summarization\", summarization_node)\n",
        "\n",
        "# Add edges to the graph\n",
        "workflow.set_entry_point(\"classification\")\n",
        "workflow.add_edge(\"classification\", \"entity_extraction\") \n",
        "workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
        "workflow.add_edge(\"summarization\", END)\n",
        "\n",
        "app = workflow.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the workflow graph\n",
        "display(\n",
        "    Image(\n",
        "        app.get_graph().draw_mermaid_png(\n",
        "            draw_method=MermaidDrawMethod.API,\n",
        "        )\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the workflow\n",
        "sample_text = \"\"\"\n",
        "OpenAI has announced the GPT-4 model, which is a large multimodal model that exhibits human-level performance on various professional benchmarks. It is developed to improve the alignment and safety of AI systems.\n",
        "additionally, the model is designed to be more efficient and scalable than its predecessor, GPT-3. The GPT-4 model is expected to be released in the coming months and will be available to the public for research and development purposes.\n",
        "\"\"\"\n",
        "\n",
        "state_input = {\"text\": sample_text}\n",
        "result = app.invoke(state_input)\n",
        "\n",
        "print(\"Classification:\", result[\"classification\"])\n",
        "print(\"\\nEntities:\", result[\"entities\"])\n",
        "print(\"\\nSummary:\", result[\"summary\"])\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
